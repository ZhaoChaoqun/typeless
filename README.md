<p align="center">
  <img src="https://img.icons8.com/fluency/96/microphone.png" width="80" />
</p>

<h1 align="center">Typeless</h1>

<p align="center">
  <strong>Press. Speak. Type.</strong><br>
  A native macOS voice-to-text tool powered by local Whisper AI
</p>

<p align="center">
  <a href="#"><img src="https://img.shields.io/badge/platform-macOS%2014.0+-blue?logo=apple&logoColor=white" alt="Platform"></a>
  <a href="#"><img src="https://img.shields.io/badge/Swift-5.9-orange?logo=swift&logoColor=white" alt="Swift"></a>
  <a href="#"><img src="https://img.shields.io/badge/license-MIT-green" alt="License"></a>
  <a href="#"><img src="https://img.shields.io/badge/AI-WhisperKit-purple" alt="WhisperKit"></a>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#installation">Installation</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#contributing">Contributing</a>
</p>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¤ **Push-to-Talk** | Hold `Fn` key to record, release to transcribe |
| ğŸ”’ **100% Local** | Whisper model runs entirely on-device, no data leaves your Mac |
| ğŸŒ **Multilingual** | Native support for Chinese-English mixed input |
| âš¡ **Fast & Lightweight** | Menu bar app with minimal resource usage |
| ğŸ¯ **Universal Input** | Works in any app - just position your cursor and speak |

## ğŸ–¥ï¸ System Requirements

| Requirement | Specification |
|-------------|---------------|
| **OS** | macOS 14.0 (Sonoma) or later |
| **Chip** | Apple Silicon (M1/M2/M3/M4) or Intel |
| **RAM** | 8GB+ recommended |

> **Note**: Apple Silicon Macs will utilize the Neural Engine for faster inference.

## ğŸ“¦ Installation

### Build from Source

```bash
# Clone the repository
git clone https://github.com/ZhaoChaoqun/typeless.git
cd typeless

# Open in Xcode
open Typeless.xcodeproj

# Or build via command line
xcodebuild -project Typeless.xcodeproj -scheme Typeless build
```

### First Launch Setup

On first launch, you'll need to grant two permissions:

| Permission | Purpose | How to Enable |
|------------|---------|---------------|
| ğŸ™ï¸ **Microphone** | Record your voice | System Prompt (automatic) |
| â™¿ **Accessibility** | Listen for global `Fn` key | System Settings â†’ Privacy & Security â†’ Accessibility |

> **Tips**: After granting Accessibility permission, you may need to restart the app.

## ğŸš€ Usage

<table>
<tr>
<td width="60%">

### Quick Start

1. **Launch** Typeless - it appears in your menu bar
2. **Hold** the `Fn` key and start speaking
3. **Release** the `Fn` key when done
4. **Text** is automatically inserted at cursor position

### Workflow Example

```
[Hold Fn] â†’ "Hello, this is a test" â†’ [Release Fn]
                    â†“
         "Hello, this is a test" appears at cursor
```

</td>
<td width="40%">

### Status Indicators

| State | Indicator |
|-------|-----------|
| Ready | ğŸµ Menu bar icon |
| Recording | ğŸ”´ Visual overlay |
| Processing | â³ Loading indicator |

</td>
</tr>
</table>

## ğŸ—ï¸ Architecture

```
typeless/
â”œâ”€â”€ Sources/
â”‚   â”œâ”€â”€ TypelessApp.swift      # App entry & lifecycle
â”‚   â”œâ”€â”€ RecordingManager.swift # Audio recording & WhisperKit
â”‚   â”œâ”€â”€ KeyMonitor.swift       # Global Fn key detection
â”‚   â”œâ”€â”€ TextInserter.swift     # Cursor text insertion
â”‚   â”œâ”€â”€ OverlayWindow.swift    # Recording UI overlay
â”‚   â””â”€â”€ SettingsView.swift     # Preferences UI
â”œâ”€â”€ Package.swift              # Swift Package dependencies
â””â”€â”€ Typeless.xcodeproj/        # Xcode project
```

### Tech Stack

| Component | Technology |
|-----------|------------|
| **UI Framework** | SwiftUI |
| **Speech Recognition** | [WhisperKit](https://github.com/argmaxinc/WhisperKit) (OpenAI Whisper) |
| **Audio Capture** | AVFoundation |
| **Key Monitoring** | CGEvent Tap API |
| **Text Insertion** | CGEvent (Keyboard Simulation) |

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fn Key     â”‚â”€â”€â”€â”€â–¶â”‚   Record     â”‚â”€â”€â”€â”€â–¶â”‚  WhisperKit â”‚â”€â”€â”€â”€â–¶â”‚   Insert     â”‚
â”‚  Monitor    â”‚     â”‚   Audio      â”‚     â”‚  Transcribe â”‚     â”‚   Text       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    CGEvent           AVFoundation         Local AI           CGEvent
```

## ğŸ”§ Configuration

The app uses the `base` Whisper model by default, offering a good balance between speed and accuracy for Chinese-English mixed content.

| Model | Size | Speed | Accuracy | Best For |
|-------|------|-------|----------|----------|
| `tiny` | ~40MB | âš¡âš¡âš¡ | â­â­ | Quick notes |
| `base` | ~140MB | âš¡âš¡ | â­â­â­ | Daily use (default) |
| `small` | ~460MB | âš¡ | â­â­â­â­ | Higher accuracy |

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [WhisperKit](https://github.com/argmaxinc/WhisperKit) - Swift implementation of OpenAI's Whisper
- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition model

---

<p align="center">
  Made with â¤ï¸ for the macOS community
</p>
